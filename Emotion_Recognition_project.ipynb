{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNcRuVeMeX4P3XpATGTdi0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatima448/Emotion_Recognition_project/blob/main/Emotion_Recognition_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTXhZxSx3AWw",
        "outputId": "1b638760-1000-410b-d8d5-2f747945ecfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/facial expression recognition.v1i.yolov8.zip\"\n",
        "extract_path = \"/content/dataset_yolo\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIdj9AJd5as9",
        "outputId": "f8cb7e89-c887-48f9-a3dc-863b89cb6123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to: /content/dataset_yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base = \"/content/dataset_yolo\"\n",
        "\n",
        "class_map = {\n",
        "    \"0\": \"angry\",\n",
        "    \"1\": \"happy\",\n",
        "    \"2\": \"neutral\",\n",
        "    \"3\": \"sad\"\n",
        "}\n",
        "\n",
        "# New structured dataset for CNN classification\n",
        "output_dir = \"/content/classification_dataset\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for cls in class_map.values():\n",
        "    os.makedirs(f\"{output_dir}/{cls}\", exist_ok=True)\n",
        "\n",
        "print(\"Created classification folders:\", os.listdir(output_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnX-Y2PB9waK",
        "outputId": "1d727f79-1241-4eaf-fd8b-c7643a4362d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created classification folders: ['neutral', 'happy', 'angry', 'sad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "image_paths = glob.glob(base + \"/**/images/*.jpg\", recursive=True)\n",
        "label_paths = glob.glob(base + \"/**/labels/*.txt\", recursive=True)\n",
        "\n",
        "label_dict = {}\n",
        "\n",
        "# Read YOLO label files and extract class IDs\n",
        "for label_file in label_paths:\n",
        "    with open(label_file, \"r\") as f:\n",
        "        line = f.readline().strip()\n",
        "    class_id = line.split(\" \")[0]  # first value in YOLO label\n",
        "\n",
        "    # image with same name\n",
        "    img_file = label_file.replace(\"labels\", \"images\").replace(\".txt\", \".jpg\")\n",
        "\n",
        "    # store mapping\n",
        "    label_dict[img_file] = class_map.get(class_id)\n",
        "\n",
        "# Copy images to classification folders\n",
        "count = 0\n",
        "for img_path, cls in label_dict.items():\n",
        "    if cls:\n",
        "        shutil.copy(img_path, f\"{output_dir}/{cls}/\")\n",
        "        count += 1\n",
        "\n",
        "print(\"Conversion complete! Total images copied:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbVh5tuQ-Fb7",
        "outputId": "730496d2-7d2c-423f-f1aa-0cb664e939f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion complete! Total images copied: 3345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 48\n",
        "X = []\n",
        "y = []\n",
        "classes = [\"angry\", \"happy\", \"neutral\", \"sad\"]\n",
        "\n",
        "for idx, cls in enumerate(classes):\n",
        "    folder = f\"{output_dir}/{cls}\"\n",
        "    for file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, file)\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = img / 255.0\n",
        "\n",
        "        X.append(img)\n",
        "        y.append(idx)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHBrVZkl_MHz",
        "outputId": "c2f74eaf-5686-4ad4-efac-2507e0e6ea59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (3345, 48, 48, 1)\n",
            "Labels shape: (3345,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 90% train, 10% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.10, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=4)\n",
        "y_test = to_categorical(y_test, num_classes=4)\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bCEikoj_bmk",
        "outputId": "094c08cd-a52e-4239-a71b-e42b030a71d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3010, 48, 48, 1) (3010, 4)\n",
            "Test: (335, 48, 48, 1) (335, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "5pDyCXWFFWh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "EX0fnYqxAPTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "cT3-M_NMFmst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "J3A6yJbOFph_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_split=0.10\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKHJucElAlBs",
        "outputId": "20a3f7de-965c-4282-a161-59e8f411e310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - accuracy: 0.2668 - loss: 1.3884 - val_accuracy: 0.3920 - val_loss: 1.3489\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - accuracy: 0.3618 - loss: 1.3379 - val_accuracy: 0.3920 - val_loss: 1.2666\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.3988 - loss: 1.2811 - val_accuracy: 0.4286 - val_loss: 1.2381\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.3994 - loss: 1.2555 - val_accuracy: 0.4286 - val_loss: 1.1760\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 185ms/step - accuracy: 0.4358 - loss: 1.2179 - val_accuracy: 0.4186 - val_loss: 1.1549\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.4590 - loss: 1.1486 - val_accuracy: 0.4385 - val_loss: 1.2091\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - accuracy: 0.4739 - loss: 1.1552 - val_accuracy: 0.4684 - val_loss: 1.1216\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.5164 - loss: 1.0992 - val_accuracy: 0.4651 - val_loss: 1.1314\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.5314 - loss: 1.0511 - val_accuracy: 0.4452 - val_loss: 1.1525\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 185ms/step - accuracy: 0.5510 - loss: 1.0362 - val_accuracy: 0.4817 - val_loss: 1.1022\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step - accuracy: 0.5820 - loss: 0.9762 - val_accuracy: 0.4884 - val_loss: 1.0886\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.5967 - loss: 0.9222 - val_accuracy: 0.5083 - val_loss: 1.0679\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 199ms/step - accuracy: 0.6190 - loss: 0.9032 - val_accuracy: 0.5116 - val_loss: 1.0964\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 194ms/step - accuracy: 0.6608 - loss: 0.8145 - val_accuracy: 0.5349 - val_loss: 1.0871\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.6697 - loss: 0.8009 - val_accuracy: 0.5150 - val_loss: 1.0896\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - accuracy: 0.6960 - loss: 0.7418 - val_accuracy: 0.5482 - val_loss: 1.0706\n",
            "Epoch 17/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 184ms/step - accuracy: 0.7050 - loss: 0.7241 - val_accuracy: 0.5382 - val_loss: 1.1118\n",
            "Epoch 18/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - accuracy: 0.7611 - loss: 0.6204 - val_accuracy: 0.5282 - val_loss: 1.0907\n",
            "Epoch 19/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.7615 - loss: 0.6055 - val_accuracy: 0.5382 - val_loss: 1.1574\n",
            "Epoch 20/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - accuracy: 0.7772 - loss: 0.5596 - val_accuracy: 0.5449 - val_loss: 1.1628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_more = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhxsKITsMeCE",
        "outputId": "e6e9de18-d708-43c3-9a21-b6567e7849da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.7709 - loss: 0.5328 - val_accuracy: 0.5482 - val_loss: 1.1584\n",
            "Epoch 2/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 181ms/step - accuracy: 0.8167 - loss: 0.4652 - val_accuracy: 0.5216 - val_loss: 1.1967\n",
            "Epoch 3/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8313 - loss: 0.4185 - val_accuracy: 0.5382 - val_loss: 1.2565\n",
            "Epoch 4/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.8418 - loss: 0.4044 - val_accuracy: 0.5216 - val_loss: 1.3229\n",
            "Epoch 5/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - accuracy: 0.8674 - loss: 0.3593 - val_accuracy: 0.5515 - val_loss: 1.3935\n",
            "Epoch 6/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.8920 - loss: 0.3037 - val_accuracy: 0.5382 - val_loss: 1.4110\n",
            "Epoch 7/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.8910 - loss: 0.2856 - val_accuracy: 0.5482 - val_loss: 1.6161\n",
            "Epoch 8/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - accuracy: 0.9086 - loss: 0.2663 - val_accuracy: 0.5382 - val_loss: 1.6716\n",
            "Epoch 9/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.9128 - loss: 0.2251 - val_accuracy: 0.5150 - val_loss: 1.8356\n",
            "Epoch 10/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.9176 - loss: 0.2207 - val_accuracy: 0.5050 - val_loss: 1.7702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhGQu_6WBqlE",
        "outputId": "9f0d0b4a-5923-42f6-f070-d35c432be59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5261 - loss: 1.7905\n",
            "Test Accuracy: 0.5402985215187073\n"
          ]
        }
      ]
    }
  ]
}